[{"title":"Planning","layout":"default","content":"<h1 id=\"planning\">Planning</h1>\n\n<p>This section focuses on considerations to review when you plan your migration.</p>\n\n<h2 id=\"migration-tools\">Migration tools</h2>\n\n<h3 id=\"migration-toolkit-for-containers\">Migration Toolkit for Containers</h3>\n\n<p>The Migration Toolkit for Containers (MTC) migrates an application workload, including Kubernetes resources, data, and images, from an OpenShift 3 source cluster to an OpenShift 4 target cluster.</p>\n\n<p>MTC performs the migration in two stages:</p>\n\n<ol>\n <li>The application workload is backed up from the source cluster to object storage.</li>\n <li>The application workload is restored to the target cluster from object storage.</li>\n</ol>\n\n<p><strong>Migrating Kubernetes resources</strong></p>\n\n<p>MTC migrates all namespaced resources, including Custom Resources. MTC can dynamically discover all the API resources in each referenced namespace.</p>\n\n<p>MTC migrates some cluster-scoped resources. If a namespaced resource references a cluster-scoped resource, it is migrated. Migratable resources include persistent volumes (PVs) bound to a persistent volume claim, cluster role bindings, and security context constraints (SCCs).</p>\n\n<p><strong>Migrating persistent volume data</strong></p>\n\n<p>MTC has two options for migrating persistent volume data:</p>\n\n<ul>\n <li>\n <p><strong>Move</strong>: The PV definition is moved from the source cluster to the target cluster without touching the data. This is the fastest option.</p>\n </li>\n <li>\n <p><strong>Copy</strong>: MTC copies either a <em>snapshot</em> or the <em>file system</em> of the PV.</p>\n </li>\n</ul>\n\n<p>See <a href=\"./running-the-migration.md#pv-move\">PV move</a> and <a href=\"./running-the-migration.md#pv-move\">PV copy</a> for requirements and details.</p>\n\n<p><strong>Migrating internal images</strong></p>\n\n<p>Internal images created by S2I builds are migrated. Each image stream reference in a given namespace is copied to the internal registry of the target cluster.</p>\n\n<h4 id=\"when-to-use-mtc\">When to use MTC</h4>\n\n<p>Ideally, you could migrate an application from one cluster to another by redeploying the application from a pipeline and perhaps copying the persistent volume data.</p>\n\n<p>However, this might not be possible in the real world. A running application on the cluster might experience unforeseen changes and, over a period of time, drift away from the initial deploy. MTC can handle scenarios where you are not certain what your namespace contains and you want to migrate all its contents to a new cluster.</p>\n\n<p>If you can redeploy your application from pipeline, that is the best option. If not, you should use MTC.</p>\n\n<h4 id=\"mtc-documentation\">MTC documentation</h4>\n\n<ul>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-application-workloads-3-4.html#migration-prerequisites_migrating-3-4\">Prerequisites</a></li>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-application-workloads-3-4.html#migration-understanding-cam_migrating-3-4\">About MTC</a></li>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-application-workloads-3-4.html#migration-understanding-data-copy-methods_migrating-3-4\">About data copy methods</a></li>\n</ul>\n\n<h2 id=\"migration-environment-considerations\">Migration environment considerations</h2>\n\n<p>OpenShift 4 introduces architectural changes and enhancements. The procedures that you used to manage your OpenShift 3 cluster might not apply to OpenShift 4.</p>\n\n<p>You should review the following considerations:</p>\n\n<ul>\n <li>Important differences between OpenShift 3 and 4 and their impact on migration (<a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-differences-architecture\">Architecture</a>, <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-differences-install\">Installation and update</a>)</li>\n <li>How stored data will be migrated for stateful applications (<a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-preparing-storage\">Storage</a>)</li>\n <li>How much downtime your application can tolerate during migration (<a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-preparing-networking\">Networking</a>)</li>\n <li>How traffic will be redirected during migration (<a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-preparing-logging\">Logging</a>, <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-preparing-security\">Security</a>, <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-preparing-monitoring\">Monitoring</a>, <a href=\"#dns-considerations\">DNS</a>)</li>\n</ul>\n\n<h2 id=\"dns-considerations\">DNS considerations</h2>\n\n<p>In a typical migration scenario, the DNS domain of the OpenShift 4 target cluster is usually different from the OpenShift 3 source cluster. This implies that the migrated applications will be have new URLs.</p>\n\n<p>If the source cluster uses the base domain <strong>ocp3.example.com</strong> and if the default domain of the applications is <strong>*.apps.ocp3.example.com</strong>, unless special measures are taken, the target cluster must be deployed on a different domain to avoid conflicts: <strong>ocp4.example.com</strong>, with the default applications defined as <strong>*.apps.ocp4.example.com</strong>.</p>\n\n<p>An application that uses the URL <code class=\"language-plaintext highlighter-rouge\">http://app1.apps.ocp3.example.com</code> in the source cluster will, after migration, use the URL <code class=\"language-plaintext highlighter-rouge\">http://app1.apps.ocp4.example.com</code>. In most cases, this is not a desirable result. The application clients must discover the new URL and adapt to it, which may not be a trivial or convenient thing to do.</p>\n\n<p>If preserving the DNS domain of migrated applications is a requirement, several options are possible.</p>\n\n<p>Once an OpenShift 4 cluster has been installed, its default DNS domain cannot be changed for a number of reasons:</p>\n\n<ul>\n <li>\n <p>Creating a route without specifying the host name parameter will use the default DNS domain for the target cluster (<strong>*.apps.ocp4.example.com</strong>). This can cause confusion when deploying a new application, especially after applying any of the options described next to have the migrated applications in the original source DNS domain.</p>\n </li>\n <li>\n <p>Internal services provided by the cluster like the web console, open authentication, alert manager, and metrics will use the default DNS domain in their URLs. With the exception of the web console, these URLs cannot be easily changed.</p>\n </li>\n</ul>\n\n<h3 id=\"option-1-isolate-the-dns-domain-of-the-target-cluster-from-the-clients\">Option 1: Isolate the DNS domain of the target cluster from the clients</h3>\n\n<p>To hide the OpenShift 4 DNS domain from the clients, a network element like an application load balancer or a reverse proxy is placed between the clients and the OpenShift 4 cluster.</p>\n\n<p>The applications are migrated from the source to the target cluster and receive a FQDN in the default DNS domain of the target cluster (app1.apps.ocp4.example.com).</p>\n\n<p>The original application FQDN (<strong>app1.apps.ocp3.example.com</strong>) is updated in the DNS server to return the IP address of the network device. The network device contains rules to send requests received for the application in the source domain to the load balancer in the target cluster, using the target cluster domain.</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>app1.apps.ocp3.example.com ---|reverse proxy|---&gt;  app1.apps.ocp4.example.com\n</code></pre>  </div></div>\n\n<p>The applications can be migrated using any of the network strategies described in <a href=\"#network-traffic-migration-strategies\">Network traffic migration strategies</a>.</p>\n\n<p>You can migrate one application at a time, creating a wildcard DNS record for the <strong>*.apps.ocp3.example.com</strong> domain that points to the IP address of the load balancer of the source cluster. You then create a specific DNS record for each application, which points to the IP address of the network device in front of the target cluster. Because a specific DNS record has higher priority than a wildcard record, no conflict arises when the application FQDN is resolved.</p>\n\n<p>Some additional considerations for this option are:</p>\n\n<ul>\n <li>\n <p>The network device must terminate all secure TLS connections. Otherwise, if the connections are passed through to the OpenShift load balancer, the FQDN of the target application will be exposed to the client and certificate errors will occur.</p>\n </li>\n <li>\n <p>The applications must support this configuration and they must not return links referencing the target cluster domain to the clients. If such links are leaked back to the client within the returned content, parts of the application may not load or work properly.</p>\n </li>\n</ul>\n\n<h3 id=\"option-2-set-up-the-target-cluster-to-accept-the-source-dns-domain\">Option 2: Set up the target cluster to accept the source DNS domain</h3>\n\n<p>You can set up the target cluster to accept requests for migrated applications in the same DNS domain that was defined in the source cluster.</p>\n\n<ul>\n <li>\n <p>Non-secure (HTTP) access:</p>\n\n <ul>\n <li>\n <p>In order for the router in the default ingress controller of the target cluster to accept requests for applications in the source DNS domain (app1.apps.ocp3.example.com), you must create a route in the application’s project for the host name that was used in the source cluster:</p>\n\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc expose svc app1-svc  <span class=\"nt\">--hostname</span> app1.apps.ocp3.example.com <span class=\"se\">\\</span>\n <span class=\"nt\">-n</span> app1-namespace\n</code></pre>  </div> </div>\n\n <p>With this new route in place, any request for that FQDN will be accepted and sent to the corresponding application pods.</p>\n\n <p>When the application is migrated, a route is created in the target cluster domain (app1.apps.ocp4.example.com). The migrated application can be accessed using both of these host names.</p>\n </li>\n <li>\n <p>You must create a specific DNS record for the FQDN defined in the route host name parameter that points to the IP address of the default load balancer of the target cluster. Specific DNS records take priority over wildcard records.</p>\n </li>\n </ul>\n\n <p>The FQDN of the application will resolve to the load balancer of the target cluster. Requests for that FQDN will be accepted by the default ingress controller router because a route for that host name is exposed.</p>\n </li>\n <li>\n <p>Secure TLS access:</p>\n\n <p>If the application requires a TLS/HTTPS connection, an additional step is required after you have created the route and DNS records:</p>\n\n <ul>\n <li>Replace the <a href=\"https://docs.openshift.com/container-platform/4.7/security/certificates/replacing-default-ingress-certificate.html\">x509 certificate of the default ingress controller</a> created during the installation process with a custom certificate that includes the wildcard DNS domains for both the source and target clusters in the Subject Alternative Name (SAN) field. The new certificate will be valid for securing connections made using either of the two DNS domains.</li>\n </ul>\n\n <p>The certificate must be updated when it approaches its expiration date.</p>\n </li>\n</ul>\n\n<h3 id=\"option-3-deploy-the-target-cluster-in-the-source-cluster-domain\">Option 3: Deploy the target cluster in the source cluster domain</h3>\n\n<p>Depending on configuration and base DNS domain of the source OpenShift 3 cluster, it might be possible to deploy the target OpenShift 4 cluster in the same DNS domain as the source cluster, using a combination of specific and wildcard DNS entries and public and private DNS zones to avoid conflicts between the clusters.</p>\n\n<p>This option requires careful planning and execution. If it is a viable option, it produces the best results. After migrating the applications, no maintenance of custom certificates, DNS entries, or external network devices is required.</p>\n\n<p>Details about this option are beyond the scope of this document. Contact Red Hat Support for more information.</p>\n\n<h2 id=\"migration-workflows\">Migration workflows</h2>\n\n<h3 id=\"mtc-workflow\">MTC workflow</h3>\n\n<p>MTC migrates applications from OCP 3 to OCP 4 in production and non-production environments.</p>\n\n<p>The following diagram describes the MTC workflow:</p>\n\n<p><img src=\"./images/mtc-promotion-flow.png\" alt=\"MTC-based\" /></p>\n\n<h3 id=\"cicd-workflow\">CI/CD workflow</h3>\n\n<p>A CI/CD pipeline deploys applications on OCP 4 production and non-production environments.</p>\n\n<p>The following diagram describes a CI/CD workflow:</p>\n\n<p><img src=\"./images/ci-cd-promotion-flow.png\" alt=\"CI-CD-based\" /></p>\n\n<h2 id=\"network-traffic-migration-strategies\">Network traffic migration strategies</h2>\n\n<p>This section describes strategies for migrating network traffic for stateless applications.</p>\n\n<p>Each strategy is based on this scenario:</p>\n\n<ul>\n <li>Applications are deployed on the 4.x cluster.</li>\n <li>If necessary, the 4.x router default certificate includes the 3.x wildcard SAN.</li>\n <li>Each application adds an additional route with the 3.x host name.</li>\n <li>Optional: The route with the 3.x host name contains an appropriate certificate.</li>\n</ul>\n\n<h3 id=\"big-bang-migration\">“Big Bang” migration</h3>\n\n<p>At migration, the 3.x wildcard DNS record is changed to point to the 4.x router virtual IP address (VIP).</p>\n\n<p><img src=\"./images/migration-strategy-bigbang.png\" alt=\"BigBang\" /></p>\n\n<h3 id=\"individual-applications\">Individual applications</h3>\n\n<p>At migration, a new record is created for each application with the 3.x FQDN/host name pointing to the 4.x router VIP. This record takes precedence over the 3.x wildcard DNS record.</p>\n\n<p><img src=\"./images/migration-strategy-individual.png\" alt=\"Individual\" /></p>\n\n<h3 id=\"canary-style-migration-of-individual-applications\">Canary-style migration of individual applications</h3>\n\n<p>A VIP/proxy with two back ends, the 3.x router VIP and the 4.x router VIP, is created for each application.</p>\n\n<p>At migration, a new record is created for each application with the 3.x FQDN/host name pointing to the VIP/proxy. This record takes precedence over the 3.x wildcard DNS record.</p>\n\n<p>The proxy entry for the application is configured to route <code class=\"language-plaintext highlighter-rouge\">X</code>% of the traffic to the 3.x router VIP and (100-<code class=\"language-plaintext highlighter-rouge\">X</code>)% of the traffic to the 4.x VIP.</p>\n\n<p><code class=\"language-plaintext highlighter-rouge\">X</code> is gradually moved from <code class=\"language-plaintext highlighter-rouge\">100</code> to <code class=\"language-plaintext highlighter-rouge\">0</code>.</p>\n\n<p><img src=\"./images/migration-strategy-canary.png\" alt=\"Canary\" /></p>\n\n<h3 id=\"audience-based-migration-of-individual-applications\">Audience-based migration of individual applications</h3>\n\n<p>A VIP/proxy with two back ends, the 3.x router VIP and the 4.x router VIP, is created for each application.</p>\n\n<p>At migration, a new record is created for each application with the 3.x FQDN/host name pointing to the VIP/proxy. This record takes precedence over the 3.x wildcard DNS record.</p>\n\n<p>The proxy entry for the application is configured to route traffic matching a given header pattern, for example, test customers, to the 4.x router VIP and the rest of the traffic to the 3.x VIP.</p>\n\n<p>Traffic is moved to the 4.x VIP in waves until all the traffic is on the 4.x VIP.</p>\n\n<p><img src=\"./images/migration-strategy-audience.png\" alt=\"Audience\" /></p>\n","dir":"/","name":"01-planning.md","path":"01-planning.md","url":"/01-planning.html"},{"title":"Cluster health checks","layout":"default","content":"<h1 id=\"cluster-health-checks\">Cluster health checks</h1>\n\n<p>This section contains a list of checks to run on your OpenShift 3.9+ source and 4.x target clusters before migration. The purpose of these checks is to detect issues that might affect the migration process.</p>\n\n<p>This list is not comprehensive and the verification of these checks does not guarantee a successful migration. We recommend getting in contact with the support team before migrating a cluster from OpenShift 3 to 4, especially if the cluster is in a production environment.</p>\n\n<h2 id=\"general-health\">General health</h2>\n\n<h3 id=\"source-cluster\">Source cluster</h3>\n\n<p>You can perform the following health checks on an OpenShift 3.9+ source cluster:</p>\n\n<ul>\n <li>Check that the OpenShift <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-application-workloads-3-4.html#migration-prerequisites_migrating-3-4\">version is supported</a> by the migration tool.</li>\n <li>Verify that all nodes in the OpenShift cluster contain an active OpenShift Container Platform subscription. This will avoid issues in case support needs to be contacted.</li>\n <li>Install and configure <a href=\"https://docs.openshift.com/container-platform/3.11/install_config/prometheus_cluster_monitoring.html\">Prometheus cluster monitoring</a>. Prometheus provides a detailed view of the health of the cluster components.</li>\n <li>\n <p>Check the node status to verify that all nodes are in a <strong>Ready</strong> state:</p>\n\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get nodes\n</code></pre>  </div> </div>\n </li>\n <li>\n <p>Check the persistent volumes (PVs):</p>\n\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get pv\n</code></pre>  </div> </div>\n\n <ul>\n <li>Mounted PVs</li>\n <li>Unmounted PVs</li>\n <li>Abnormal configurations</li>\n <li>PVs stuck in terminating state</li>\n </ul>\n </li>\n <li>\n <p>Check pods for status that is not <strong>Running</strong> or <strong>Completed</strong>. Use the following command because pods might not display an error state:</p>\n\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get pods <span class=\"nt\">--all-namespaces</span>|egrep <span class=\"nt\">-v</span> <span class=\"s1\">'Running | Completed'</span>\n</code></pre>  </div> </div>\n </li>\n <li>Check for pods with a high restart count. Even if they are in a <strong>Running</strong> state, a high restart count might indicate underlying problems.\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"c\"># Get pods with a restartCount above 3</span>\n<span class=\"nv\">$ </span>oc get pods <span class=\"nt\">--all-namespaces</span> <span class=\"nt\">--field-selector</span><span class=\"o\">=</span>status.phase<span class=\"o\">=</span>Running <span class=\"nt\">-o</span> json | jq <span class=\"s1\">'.items[]|select(any( .status.containerStatuses[]; .restartCount &gt; 3))|.metadata.name'</span>\n</code></pre>  </div> </div>\n </li>\n <li>Check the <a href=\"https://access.redhat.com/articles/3093761\">health of the <strong>etcd</strong> cluster</a>.</li>\n <li>Check the <a href=\"https://docs.openshift.com/container-platform/3.11/day_two_guide/environment_health_checks.html#connectivity-on-master-hosts\">network connectivity</a> between master hosts.</li>\n <li>Check the <a href=\"https://docs.openshift.com/container-platform/3.11/day_two_guide/environment_health_checks.html#day-two-guide-api-service-status\">API service status</a>.</li>\n <li>Check that the cluster certificates are not close to expiration and will be valid for the duration of the migration process. You can use the <a href=\"https://docs.openshift.com/container-platform/3.11/install_config/redeploying_certificates.html#install-config-cert-expiry\"><code class=\"language-plaintext highlighter-rouge\">easy-mode</code> Ansible playbook</a> to check the certificates.</li>\n <li>\n <p>Check for pending certificate signing requests:</p>\n\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get csr\n</code></pre>  </div> </div>\n </li>\n <li>Check that <a href=\"https://docs.openshift.com/container-platform/3.11/day_two_guide/run_once_tasks.html#day-two-guide-ntp-synchronization\">time synchronization</a> is consistent across the whole cluster.</li>\n <li>Check that the internal container image registry is healthy, images can be read from and written to it.</li>\n <li>Check that the internal container image registry uses a <a href=\"https://docs.openshift.com/container-platform/3.11/scaling_performance/optimizing_storage.html#registry\">supported storage type</a>.</li>\n <li>Check that applications are not using <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/troubleshooting-3-4.html#migration-gvk-incompatibility_migrating-3-4\">deprecated Kubernetes API references</a>. MTC will warn you about any resources using deprecated Kubernetes API references.</li>\n <li>Check that all nodes in the cluster have <a href=\"https://docs.openshift.com/container-platform/3.11/day_two_guide/run_once_tasks.html#day-two-guide-entropy\">high entropy value</a>.</li>\n</ul>\n\n<h3 id=\"target-cluster\">Target cluster</h3>\n\n<p>You can perform the following health checks on an OpenShift 4.x target cluster:</p>\n\n<ul>\n <li>\n <p>Check that the cluster has access to external services required by the applications by verifying network connectivity and proper permissions.</p>\n\n <p>Examples of external services include databases, source code repositories, container image registries, and CI/CD tools.</p>\n </li>\n <li>Check that external applications, services, and appliances that use services provided by the target cluster have access and proper permissions.</li>\n <li>\n <p>Verify that all internal container image dependencies are met.</p>\n\n <p>If an application requires an image that is not in the application namespace, check that the image exists. For example, an application that uses the <code class=\"language-plaintext highlighter-rouge\">php:7.1</code> base image from the PHP image stream on an OpenShift 3.11 cluster will not work on an OpenShift 4.x cluster because that particular version is not included in the PHP image stream for OpenShift 4. See <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-application-workloads-3-4.html#migration-prerequisites_migrating-3-4\">migration prerequisites</a> for a list of image stream tags that have been removed from OpenShift 4.2.</p>\n\n <p>You can <a href=\"#manually-updating-images-from-openshift-3-to-4\">manually update the image stream tag of internal images</a> from OpenShift 3 to 4 with Podman.</p>\n </li>\n</ul>\n\n<h2 id=\"resource-capacity\">Resource capacity</h2>\n\n<ul>\n <li>The clusters require additional memory, CPUs, and storage in order to run a migration on top of normal workloads. Actual resource requirements depend on the number of Kubernetes resources being migrated in a single migration plan.</li>\n <li>Check that the OpenShift 3.9+ source cluster meets the <a href=\"https://docs.openshift.com/container-platform/3.11/install/prerequisites.html#hardware\">minimum hardware requirements</a> for an OpenShift installation.</li>\n <li>Check that the OpenShift 4.x target cluster meets the minimum hardware requirements for the specific platform and installation method. For example, a bare metal installation has <a href=\"https://docs.openshift.com/container-platform/4.7/installing/installing_bare_metal/installing-bare-metal.html#minimum-resource-requirements_installing-bare-metal\">specific minimum resource requirements</a>.</li>\n <li>Verify that the OpenShift 4.x target cluster contains storage classes for the same types (block, file, object) as the OpenShift 3.9+ source cluster.</li>\n <li>Check the available bandwidth between the source and target clusters. Less than 10 Gbps is not recommended.</li>\n <li>If you are migrating more than 20 TB, check that the target cluster and the replication repository have sufficient storage.</li>\n</ul>\n\n<h2 id=\"performance\">Performance</h2>\n\n<ul>\n <li>Check cluster compute and memory utilization: <code class=\"language-plaintext highlighter-rouge\">$ oc adm top node</code>.</li>\n <li>Check the average response time of API calls in the source cluster. Less than 50 ms. is recommended.</li>\n <li>Check <code class=\"language-plaintext highlighter-rouge\">etcd</code> disk performance on the source and target clusters with <a href=\"https://access.redhat.com/solutions/4885641\"><code class=\"language-plaintext highlighter-rouge\">fio</code></a>.</li>\n</ul>\n\n<h2 id=\"additional-checks\">Additional checks</h2>\n\n<ul>\n <li>Review the <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/planning-migration-3-to-4.html#migration-considerations\">migration considerations</a> in the OpenShift documentation.</li>\n <li>Verify the identity provider on the source and target clusters.</li>\n <li>Verify the network visibility between namespaces on the OpenShift 4.x target cluster, especially if the OpenShift 3.9+ source cluster uses the <a href=\"https://docs.openshift.com/container-platform/3.11/architecture/networking/sdn.html#architecture-additional-concepts-sdn\"><strong>multitenant</strong> network plugin</a>.</li>\n <li>OpenShift 4.x uses the <a href=\"https://docs.openshift.com/container-platform/4.7/networking/network_policy/about-network-policy.html\"><strong>networkpolicy</strong> network plugin</a>, which has an open policy by default. All pods and services are accessible from any project.</li>\n</ul>\n","dir":"/","name":"02-cluster-health-checks.md","path":"02-cluster-health-checks.md","url":"/02-cluster-health-checks.html"},{"title":"Premigration testing","layout":"default","content":"<h1 id=\"premigration-testing\">Premigration testing</h1>\n\n<h2 id=\"installing-mtc\">Installing MTC</h2>\n\n<p>Install MTC on your source and target clusters:</p>\n\n<ul>\n <li>Check the <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-application-workloads-3-4.html#migration-prerequisites_migrating-3-4\">migration prerequisites</a>.</li>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/deploying-cam-3-4.html\">Install MTC</a> on the source and target clusters.</li>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/configuring-replication-repository-3-4.html\">Configure a replication repository</a>.</li>\n</ul>\n\n<p>The following diagram describes how MTC uses Velero and Restic to back up data from the source cluster to the replication repository and then restores data from the replication repository to the target cluster:</p>\n\n<p><img src=\"./images/mtc-architecture.png\" alt=\"MTC Architecture\" /></p>\n\n<h2 id=\"ensuring-same-mtc-versions\">Ensuring same MTC versions</h2>\n\n<p>The same MTC z-stream version must be installed on the source and target clusters.</p>\n\n<p>Download and re-install the MTC Operator on the OpenShift 3 cluster just before you run a migration to ensure that you have the latest version.</p>\n\n<p>The Operator Lifecycle Manager (OLM) pushes MTC Operator updates to the OpenShift 4 cluster automatically. On the OpenShift 3 cluster, however, the MTC Operator is installed manually and is not updated automatically.</p>\n\n<h2 id=\"checking-olm-managed-setting\">Checking ‘OLM Managed’ setting</h2>\n\n<p>In the web console, check the ‘OLM Managed’ setting in the ‘MigrationController’ manifest of each cluster:</p>\n\n<ul>\n <li>OpenShift 4 uses OLM:\n <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">olm_managed</span><span class=\"pi\">:</span> <span class=\"no\">true</span>\n</code></pre>  </div> </div>\n </li>\n <li>OpenShift 3 does not use OLM:\n <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">olm_managed</span><span class=\"pi\">:</span> <span class=\"no\">false</span>\n</code></pre>  </div> </div>\n </li>\n</ul>\n\n<h2 id=\"migrating-a-simple-application\">Migrating a simple application</h2>\n\n<p>Migrate a simple application without a persistent volume (PV):</p>\n\n<ol>\n <li>Install a simple application without a PV on the source cluster.</li>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-applications-with-cam-3-4.html\">Migrate the application</a> to the target cluster. You do not need to stage the migration.</li>\n <li>Validate the application on the target cluster.</li>\n</ol>\n\n<h2 id=\"migrating-an-application-with-a-persistent-volume\">Migrating an application with a persistent volume</h2>\n\n<p>Migrate an application with a PV:</p>\n\n<ol>\n <li>Install an application with an associated PV on the source cluster.</li>\n <li>Stage the migration one or more times. Staging reduces migration time and application downtime during migration.</li>\n <li>Migrate the application to the target cluster.</li>\n <li>Validate the application on the target cluster.</li>\n</ol>\n\n<h2 id=\"removing-a-migrated-application-namespace\">Removing a migrated application namespace</h2>\n\n<p>If you are performing multiple test migrations, remove the migrated application namespace from the target cluster after each test.</p>\n","dir":"/","name":"03-pre-migration-testing.md","path":"03-pre-migration-testing.md","url":"/03-pre-migration-testing.html"},{"title":"Running the migration","layout":"default","content":"<h1 id=\"running-the-migration\">Running the migration</h1>\n\n<p>This section focuses on considerations associated with creating and running a migration plan.</p>\n\n<h2 id=\"before-creating-a-migration-plan\">Before creating a migration plan</h2>\n\n<p>This section describes considerations to review before you create a migration plan.</p>\n\n<h3 id=\"migration-environment\">Migration environment</h3>\n\n<p>Prepare your migration environment by checking the following:</p>\n\n<ul>\n <li>Network:\n <ul>\n <li>Ensure that your clusters have adequate network bandwidth, especially if you are copying PVs.</li>\n <li>Ensure that <a href=\"https://docs.openshift.com/container-platform/4.7/installing/installing_bare_metal/installing-bare-metal.html#installation-infrastructure-user-infra_installing-bare-metal\">DNS records</a> for your application exist on the target cluster.</li>\n <li>Certificates: Ensure that certificates used by your application exist on the target cluster.</li>\n <li>Ensure that the appropriate <a href=\"https://docs.openshift.com/container-platform/4.7/installing/install_config/configuring-firewall.html\">firewall rules</a> are configured on the target cluster.</li>\n <li>Ensure that load balancing is correctly configured on the target cluster.</li>\n </ul>\n </li>\n <li>Resources:\n <ul>\n <li>Check whether your application uses a service network or an external route to communicate with services.</li>\n <li>If your application uses non-namespaced resources, you must re-create them on the target cluster.</li>\n <li>You must migrate images from the internal image registry if you are not using an external image registry. If they cannot be migrated, you must re-create them manually on the target cluster.</li>\n <li>Increase the <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-applications-with-cam-3-4.html#migration-changing-migration-plan-limits_migrating-3-4\">CPU and memory limits of the Migration Controller</a> for large migrations.</li>\n <li>Use the <a href=\"https://docs.openshift.com/container-platform/4.7/applications/pruning-objects.html\"><code class=\"language-plaintext highlighter-rouge\">prune</code> command</a> to remove old builds, deployments, and images from each namespace being migrated.</li>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-applications-with-cam-3-4.html#migration-excluding-resources_migrating-3-4\">Exclude PVs, image streams, and other resources</a> if you do not want to migrate them with MTC.</li>\n </ul>\n </li>\n <li>Namespaces:\n <ul>\n <li>Check the namespaces on the target cluster to ensure that they do not duplicate namespaces being migrated.</li>\n <li>Do not create namespaces for your application on the target cluster before migration because this can cause quotas to change.</li>\n </ul>\n </li>\n <li>Storage:\n <ul>\n <li>Ensure that the object storage (replication repository) has sufficient room for the PV data and images being migrated.</li>\n <li>If PV migrations are slow, check that your storage nodes have adequate input/output, CPUs, and memory.</li>\n <li>Back up PV data in case an application displays unexpected behavior after migration and corrupts the data.</li>\n </ul>\n </li>\n</ul>\n\n<h3 id=\"increasing-migration-plan-limits\">Increasing migration plan limits</h3>\n\n<p>You can <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/migrating-applications-with-cam-3-4.html#migration-changing-migration-plan-limits_migrating-3-4\">increase the limits</a> for a single migration plan, but such changes must be <em>approached with caution and thoroughly tested</em>.</p>\n\n<p>MTC has the following migration plan defaults to encourage smaller migrations:</p>\n\n<ul>\n <li>100 PVs</li>\n <li>100 pods</li>\n <li>10 namespaces</li>\n</ul>\n\n<p>These limits should only be increased if a large plan is required for migrating a namespace that contains many resources or migrating several namespaces together because of dependency issues.</p>\n\n<h3 id=\"resource-quotas\">Resource quotas</h3>\n\n<p>If you are using resource quotas, the following considerations might apply:</p>\n\n<ul>\n <li>Source cluster: If you are migrating PVs, you might have to <a href=\"https://docs.openshift.com/container-platform/4.7/applications/quotas/quotas-setting-per-project.html#quotas-creating-a-quota_quotas-setting-per-project\">increase the pod limit</a> on the source cluster. The migration process creates a temporary ‘stage’ pod on the source cluster when a PV is copied. See <a href=\"https://issues.redhat.com/browse/MIG-217\">MIG-217 - Catch error conditions of not enough quota when attempting to do a stage/migrate</a>.</li>\n <li>Target cluster: The resource quotas on the target cluster must be sufficient for the namespace that you are migrating. See <a href=\"https://issues.redhat.com/browse/MIG-203\">MIG-203 - Handle ResourceQuotas when changing storage classes, allow for possibility of keys changing</a>.</li>\n</ul>\n\n<h3 id=\"internal-images\">Internal images</h3>\n\n<p>If your application uses images from the <code class=\"language-plaintext highlighter-rouge\">openshift</code> namespace, you must ensure that the required versions of these images are present on the target cluster. MTC processes each image stream in a referenced namespace and migrates the images. Images that are not included in the image stream of a referenced namespace are not copied.</p>\n\n<p>If the required images are not present, you can update the image stream tag references to point to an available version that is compatible with your application or manually update the image stream tags.</p>\n\n<p>You can also use Podman to update an OpenShift 3 image for OpenShift 4.</p>\n\n<h4 id=\"manually-updating-an-openshift-3-internal-image-stream-for-openshift-4\">Manually updating an OpenShift 3 internal image stream for OpenShift 4</h4>\n\n<p>You can use Podman to manually tag an internal OpenShift 3 image and push it to the OpenShift 4 registry to create an image stream:</p>\n\n<ol>\n <li>Expose the internal registries on the OpenShift <a href=\"https://docs.openshift.com/container-platform/3.11/install_config/registry/securing_and_exposing_registry.html#exposing-the-registry\">3</a> and <a href=\"https://docs.openshift.com/container-platform/4.7/registry/securing-exposing-registry.html#registry-exposing-secure-registry-manually_securing-exposing-registry\">4</a> clusters.</li>\n <li>If you are using insecure registries, add your registry host values to the <code class=\"language-plaintext highlighter-rouge\">[registries.insecure]</code> section in <code class=\"language-plaintext highlighter-rouge\">/etc/container/registries.conf</code> so that Podman does not encounter a TLS verification error.</li>\n <li>Log in to both registries:\n <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> $ podman login -u $(oc whoami) -p $(oc whoami -t) --tls-verify=false $OCP3_HOST\n $ podman login -u $(oc whoami) -p $(oc whoami -t) --tls-verify=false $OCP4_HOST\n</code></pre>  </div> </div>\n </li>\n <li>Pull the OpenShift 3 image you want to tag, for example, the deprecated <code class=\"language-plaintext highlighter-rouge\">python:3.3</code> image:\n <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> $ podman pull $OCP3_HOST/openshift/python:3.3\n</code></pre>  </div> </div>\n </li>\n <li>Tag the image for the OpenShift 4 registry:\n <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> $ podman tag $OCP3_HOST/openshift/python:3.3 $OCP4_HOST/openshift/python:3.3\n</code></pre>  </div> </div>\n </li>\n <li>Push the image to the OpenShift 4 registry:\n <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> $ podman push $OCP4_HOST/openshift/python:3.3\n</code></pre>  </div> </div>\n </li>\n <li>Verify that the image has a valid image stream tag on the OpenShift 4 cluster:\n <div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> $ oc get imagestream -n openshift | grep python\n python    $OCP4_HOST/openshift/python     3.3,2.7,2.7-ubi7,2.7-ubi8,3.6-ubi8,3.8 + 3 more...      6 seconds ago\n</code></pre>  </div> </div>\n </li>\n</ol>\n\n<h3 id=\"route-host-names\">Route host names</h3>\n\n<p>If an application uses an OpenShift route, the resource is migrated to the target cluster.</p>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">openshift.io/host.generated</code> annotation determines whether the host name is updated:</p>\n\n<ul>\n <li>If <code class=\"language-plaintext highlighter-rouge\">openshift.io/host.generated</code> is set, the <a href=\"https://github.com/konveyor/openshift-velero-plugin/blob/master/velero-plugins/route/restore.go\">OpenShift Velero route plugin</a> strips the source host name from the route and updates the route with the target cluster host name.</li>\n <li>If <code class=\"language-plaintext highlighter-rouge\">openshift.io/host.generated</code> is <em>not</em> set, the route is migrated as is from the source cluster. The host name of the route <strong>is not</strong> updated.</li>\n</ul>\n\n<h3 id=\"pod-uids\">Pod UIDs</h3>\n\n<p>MTC preserves pod UIDs during the migration process by migrating the following namespace annotations:</p>\n\n<ul>\n <li><code class=\"language-plaintext highlighter-rouge\">openshift.io/sa.scc.mcs</code></li>\n <li><code class=\"language-plaintext highlighter-rouge\">openshift.io/sa.scc.supplemental-groups</code></li>\n <li><code class=\"language-plaintext highlighter-rouge\">openshift.io/sa.scc.uid-range</code></li>\n</ul>\n\n<p>These annotations preserve the UID range, ensuring that the containers retain their file system permissions on the target cluster.</p>\n\n<p>Migrated UIDs might duplicate UIDs in a current or future namespace on the target cluster. See <a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=1748531\">BZ#1748531 - Handling UID range namespace annotations when migrating an application from source to destination</a>.</p>\n\n<h2 id=\"creating-a-migration-plan\">Creating a migration plan</h2>\n\n<p>This section describes considerations to review when you create a migration plan.</p>\n\n<h3 id=\"migrate-an-application-with-its-dependencies\">Migrate an application with its dependencies</h3>\n\n<p>Check whether your application uses services, images, or resources in other namespaces.</p>\n\n<p>If the application has dependencies, you should migrate the application and the dependency namespaces in the same migration plan.</p>\n\n<h3 id=\"pv-move\">PV move</h3>\n\n<p><em>PV move</em> is faster than <em>PV copy</em>.</p>\n\n<p>MTC moves a PV by re-creating the PV definition on the target cluster. The actual data remains untouched. PV move is suitable for NFS.</p>\n\n<p>The remote storage must be accessible to both the source and target clusters.</p>\n\n<h3 id=\"pv-copy\">PV copy</h3>\n\n<p>MTC copies a snapshot or the file system of the PV.</p>\n\n<p>The following table compares the <em>snapshot</em> and <em>file system</em> copy options.</p>\n\n<table>\n <thead>\n <tr>\n <th> </th>\n <th>Snapshot copy</th>\n <th>File system copy</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <td><strong>Speed</strong></td>\n <td>Fast</td>\n <td>Slow</td>\n </tr>\n <tr>\n <td><strong>Provider support</strong></td>\n <td>AWS, Google Cloud Provider, Microsoft Azure<sup>1</sup></td>\n <td>All providers</td>\n </tr>\n <tr>\n <td><strong>Storage class changes</strong></td>\n <td>No</td>\n <td>Yes<sup>2</sup></td>\n </tr>\n <tr>\n <td><strong>Regional limitations</strong></td>\n <td>Yes<sup>3</sup></td>\n <td>No</td>\n </tr>\n </tbody>\n</table>\n\n<p><sup>1</sup> The source and target PVs must have the same cloud storage provider.</p>\n\n<p><sup>2</sup> The source and target PVs can have different storage classes.</p>\n\n<p><sup>3</sup> The source and target PVs must be in the same geographic region.</p>\n\n<h3 id=\"deprecated-apis\">Deprecated APIs</h3>\n\n<p>In OpenShift 4.x, some API GroupVersionKinds (GVKs) that are used by OpenShift 3.x are <a href=\"https://kubernetes.io/blog/2019/07/18/api-deprecations-in-1-16/\">deprecated</a>. If your source cluster contains deprecated APIs, the following error is displayed in the MTC console when you create a migration plan: <code class=\"language-plaintext highlighter-rouge\">Some namespaces contain GVKs incompatible with destination cluster</code>. You can run the migration plan but the affected resources will not be migrated.</p>\n\n<p>You can <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/troubleshooting-3-4.html#migration-gvk-incompatibility_migrating-3-4\">migrate the excluded resources manually</a> after the migration.</p>\n\n<h2 id=\"running-migration-plans\">Running migration plans</h2>\n\n<p>This section describes considerations to review when you run a migration plan.</p>\n\n<h3 id=\"run-one-migration-plan-at-a-time\">Run one migration plan at a time</h3>\n\n<p>Run <em>one</em> plan at a time. Do not try to run multiple migration plans simultaneously.</p>\n\n<p>Although the MTC Migration Controller can run multiple migration plans, Velero, which performs the backup/restore operations, currently supports only single threading.</p>\n\n<p>If you need to run different migrations, create and run the plans sequentially.</p>\n\n<h3 id=\"run-stage-migrations-to-reduce-downtime\">Run stage migrations to reduce downtime</h3>\n\n<p>Users will experience application downtime during the migration. The length of downtime depends on the size of the migration, including the number of namespaces, PVs, images, and resources in each namespace.</p>\n\n<p>Stage migrations reduce the duration of the final migration because they perform incremental backup/restore operations on PV data and images.</p>\n\n<p>You can reduce the downtime by performing stage migrations several days before the final migration:</p>\n\n<ol>\n <li>Schedule downtime for the final migration.</li>\n <li>Several days before the final migration, run stage migrations so that most of the PV and image data is copied to the target cluster.</li>\n <li>Just before the final migration, run a stage migration to copy the most recent changes to the target cluster.</li>\n <li>Quiesce the application and then run the final migration.</li>\n</ol>\n\n<p>Stage migrations normally reduce the duration of the final migration. However, if an application writes very large files, incremental backup/restore might not reduce the final migration time significantly.</p>\n\n<p><strong>Comparison of stage migration and final migration</strong></p>\n\n<p>The following table compares stage migration and final migration:</p>\n\n<table>\n <thead>\n <tr>\n <th> </th>\n <th>Stage migration</th>\n <th>Final migration</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <td><strong>Kubernetes resources</strong></td>\n <td><code class=\"language-plaintext highlighter-rouge\">No</code><sup>1</sup></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Yes</code></td>\n </tr>\n <tr>\n <td><strong>PV move</strong></td>\n <td><code class=\"language-plaintext highlighter-rouge\">No</code></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Yes</code></td>\n </tr>\n <tr>\n <td><strong>PV copy</strong></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Yes</code></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Yes</code></td>\n </tr>\n <tr>\n <td><strong>Images</strong></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Yes</code></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Yes</code></td>\n </tr>\n <tr>\n <td><strong>Application state</strong></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Running</code></td>\n <td><code class=\"language-plaintext highlighter-rouge\">Quiesced</code><sup>2</sup></td>\n </tr>\n </tbody>\n</table>\n\n<p><sup>1</sup> Exceptions: PV copy and images.\n<sup>2</sup> All pods are scaled to <code class=\"language-plaintext highlighter-rouge\">0</code> for a consistent view of the data.</p>\n\n<h3 id=\"quiescing-applications\">Quiescing applications</h3>\n\n<p>Quiescing brings an application to a consistent state so that its file system can be copied without causing data corruption.</p>\n\n<p>Deployments, deployment configuration, jobs, stateful sets, and other resources are scaled to <code class=\"language-plaintext highlighter-rouge\">0</code> if you select the <code class=\"language-plaintext highlighter-rouge\">Quiesce</code> option before running a migration plan.</p>\n\n<p>In the future, MTC might support quiescence options such as putting an application into <code class=\"language-plaintext highlighter-rouge\">read-only</code> mode.</p>\n","dir":"/","name":"04-running-the-migration.md","path":"04-running-the-migration.md","url":"/04-running-the-migration.html"},{"title":"Troubleshooting","layout":"default","content":"<h1 id=\"troubleshooting\">Troubleshooting</h1>\n\n<p>This section describes common troubleshooting procedures.</p>\n\n<p>Additional resources:</p>\n<ul>\n <li><a href=\"https://github.com/konveyor/enhancements/tree/master/enhancements/debug\">Upstream document</a> for improving debug experience</li>\n <li><a href=\"https://app.lucidchart.com/documents/view/d0907ce1-ccf1-4226-86eb-e5332f9d42a4/0_0\">MTC Debug flowchart</a> (in progress)</li>\n</ul>\n\n<h2 id=\"debugging-mtc-resources\">Debugging MTC resources</h2>\n\n<h3 id=\"mtc-custom-resources\">MTC custom resources</h3>\n\n<p>The following diagram describes the MTC debug flow.</p>\n\n<p><img src=\"./images/mtc-1.4.z-debugging-guide.jpeg\" alt=\"Debug flow\" /></p>\n\n<p>The following diagram describes the MTC custom resources (CRs). Each object is a standard Kubernetes CR.</p>\n\n<p>You can manage the MTC resources with the standard create, read, update, and delete operations using the <code class=\"language-plaintext highlighter-rouge\">kubectl</code> and <code class=\"language-plaintext highlighter-rouge\">oc</code> clients or directly, using the web interface.</p>\n\n<!-- TODO: Need to update diagram with MigAnalytic and MigHook -->\n\n<p><img src=\"./images/CRDArch.png\" alt=\"CRD Architecture\" /></p>\n\n<h3 id=\"debugging-mtc-resources-using-the-web-console\">Debugging MTC resources using the web console</h3>\n\n<p>You can view the resources of a migration plan in the MTC web console:</p>\n\n<ol>\n <li>\n <p>Click the <strong>Options</strong> menu next to a migration plan and select <strong>View migration plan resources</strong>.</p>\n\n <p>The migration plan resources are displayed as a tree.</p>\n </li>\n <li>\n <p>Click the arrow of a <strong>Backup</strong> or <strong>Restore</strong> resource to view its pods.</p>\n </li>\n <li>\n <p>Click the <strong>Copy</strong> button of a pod to copy the <code class=\"language-plaintext highlighter-rouge\">oc get</code> command to your clipboard and paste the command on the command line.</p>\n </li>\n <li>\n <p>Click <strong>View Raw</strong> to inspect a pod.</p>\n\n <p>The resource is displayed in JSON format.</p>\n </li>\n</ol>\n\n<p><img src=\"./images/ResourceDebugKebabOption.png\" alt=\"Resource Debug Kebab Option\" /></p>\n\n<p><img src=\"./images/DebugTree.png\" alt=\"Debug Tree UI\" /></p>\n\n<p>Usually the objects that you should examine depend on the stage at which the\nmigration failed. The <a href=\"https://app.lucidchart.com/documents/view/d0907ce1-ccf1-4226-86eb-e5332f9d42a4/0_0\">MTC debug flowchart</a> provides information about which resources are relevant, depending on this failure stage.</p>\n\n<p><strong>Stage migrations</strong> have one <code class=\"language-plaintext highlighter-rouge\">Backup</code> and one <code class=\"language-plaintext highlighter-rouge\">Restore</code> resource.</p>\n\n<p><strong>Final migrations</strong> have two <code class=\"language-plaintext highlighter-rouge\">Backup</code> and two <code class=\"language-plaintext highlighter-rouge\">Restore</code> resources. The first <code class=\"language-plaintext highlighter-rouge\">Backup</code> resource captures the original, unaltered state of the application and its Kubernetes objects. This <code class=\"language-plaintext highlighter-rouge\">Backup</code> is the source of truth.</p>\n\n<p>Then, the application is quiesced and a second <code class=\"language-plaintext highlighter-rouge\">Backup</code> captures the storage-related resources (PVs, PVCs, data).</p>\n\n<p>The first <code class=\"language-plaintext highlighter-rouge\">Restore</code> restores these storage objects on the target cluster. The final <code class=\"language-plaintext highlighter-rouge\">Restore</code> restores the original application <code class=\"language-plaintext highlighter-rouge\">Backup</code> to the target cluster.</p>\n\n<h3 id=\"debugging-migration-resources-from-the-command-line\">Debugging migration resources from the command line</h3>\n\n<p>You can view the migration debug tree and query specific label selectors.</p>\n\n<ul>\n <li>To view all <code class=\"language-plaintext highlighter-rouge\">migmigration</code> resources associated with the <code class=\"language-plaintext highlighter-rouge\">test</code> migration plan:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get migmigration <span class=\"nt\">-l</span> <span class=\"s1\">'migration.openshift.io/migplan-name=test'</span>\n</code></pre>  </div> </div>\n\n <p><strong>Example output</strong></p>\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>NAME                                  READY  PLAN  STAGE  ITINERARY  PHASE\n09a8bf20-fdc5-11ea-a447-cb5249018d21         <span class=\"nb\">test  false  </span>Final      Completed\n</code></pre>  </div> </div>\n <p>The columns display the associated plan name, itinerary step, and phase.</p>\n </li>\n <li>To view all completed <code class=\"language-plaintext highlighter-rouge\">migmigration</code> resources associated with the <code class=\"language-plaintext highlighter-rouge\">test</code> migration plan:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get migmigration <span class=\"nt\">-l</span> <span class=\"s1\">'migration.openshift.io/migplan-name=test'</span> <span class=\"nt\">-o</span><span class=\"se\">\\</span>\ngo-template-file<span class=\"o\">=</span>./go-cli-templates/migmigration-completed-list.template\n</code></pre>  </div> </div>\n\n <p><strong>Example output</strong></p>\n <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">Name</span><span class=\"pi\">:</span>       <span class=\"s\">51886050-6d52-11eb-98e7-b515603f1bc7</span>\n<span class=\"na\">Migplan</span><span class=\"pi\">:</span>    <span class=\"s\">test</span>\n<span class=\"na\">Result</span><span class=\"pi\">:</span>     <span class=\"s\">SucceededWithWarnings</span>\n\n<span class=\"na\">Name</span><span class=\"pi\">:</span>       <span class=\"s\">b4d045f0-6d58-11eb-98e7-b515603f1bc7</span>\n<span class=\"na\">Migplan</span><span class=\"pi\">:</span>    <span class=\"s\">test</span>\n<span class=\"na\">Result</span><span class=\"pi\">:</span>     <span class=\"s\">SucceededWithWarnings</span>\n</code></pre>  </div> </div>\n\n <p>The <code class=\"language-plaintext highlighter-rouge\">Result</code> parameter indicates a status of <code class=\"language-plaintext highlighter-rouge\">Succeeded</code>, <code class=\"language-plaintext highlighter-rouge\">SucceededWithWarnings</code>, or <code class=\"language-plaintext highlighter-rouge\">Failed</code>.</p>\n </li>\n <li>To view the warnings of all completed <code class=\"language-plaintext highlighter-rouge\">migmigration</code> resources associated with the <code class=\"language-plaintext highlighter-rouge\">test</code> migration plan:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get migmigration <span class=\"nt\">-l</span> <span class=\"s1\">'migration.openshift.io/migplan-name=test'</span> <span class=\"nt\">-o</span> <span class=\"se\">\\</span>\ngo-template-file<span class=\"o\">=</span>go-cli-templates/migmigration-display-warning-list.template\n</code></pre>  </div> </div>\n\n <p><strong>Example output</strong></p>\n <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">Name</span><span class=\"pi\">:</span>       <span class=\"s\">51886050-6d52-11eb-98e7-b515603f1bc7</span>\n<span class=\"na\">Migplan</span><span class=\"pi\">:</span>    <span class=\"s\">test</span>\n<span class=\"na\">Warning</span><span class=\"pi\">:</span>    <span class=\"s\">DirectVolumeMigrationFailed</span>\n    <span class=\"s\">Message</span><span class=\"pi\">:</span>        <span class=\"s\">DirectVolumeMigration (dvm)</span><span class=\"pi\">:</span> <span class=\"s\">openshift-migration/51886050-6d52-11eb-98e7-b515603f1bc7-z9zfj failed. See in dvm status.Errors</span>\n<span class=\"na\">errors</span><span class=\"pi\">:</span>     <span class=\"s\">&lt;no value&gt;</span>\n\n<span class=\"na\">Name</span><span class=\"pi\">:</span>       <span class=\"s\">b4d045f0-6d58-11eb-98e7-b515603f1bc7</span>\n<span class=\"na\">Migplan</span><span class=\"pi\">:</span>    <span class=\"s\">test</span>\n<span class=\"na\">Warning</span><span class=\"pi\">:</span>    <span class=\"s\">DirectVolumeMigrationFailed</span>\n    <span class=\"s\">Message</span><span class=\"pi\">:</span>        <span class=\"s\">DirectVolumeMigration (dvm)</span><span class=\"pi\">:</span> <span class=\"s\">openshift-migration/b4d045f0-6d58-11eb-98e7-b515603f1bc7-4c894 failed. See in dvm status.Errors</span>\n<span class=\"na\">errors</span><span class=\"pi\">:</span>     <span class=\"s\">&lt;no value&gt;</span>\n</code></pre>  </div> </div>\n </li>\n <li>To list all <code class=\"language-plaintext highlighter-rouge\">Backup</code> resources:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get backup <span class=\"nt\">-n</span> openshift-migration\n</code></pre>  </div> </div>\n\n <p><strong>Example output</strong></p>\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>NAME                                   AGE\n88435fe0-c9f8-11e9-85e6-5d593ce65e10   6m42s\n</code></pre>  </div> </div>\n\n <p>You can use the same command to view <code class=\"language-plaintext highlighter-rouge\">Restore</code> resources.</p>\n </li>\n <li>To inspect a <code class=\"language-plaintext highlighter-rouge\">Backup</code> resource:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc describe backup 88435fe0-c9f8-11e9-85e6-5d593ce65e10 <span class=\"nt\">-n</span> openshift-migration\n</code></pre>  </div> </div>\n </li>\n <li>To list failed migrations caused by direct volume migration failures:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get dvm <span class=\"nt\">-l</span> <span class=\"nv\">migmigration</span><span class=\"o\">=</span>&lt;uid&gt;\n</code></pre>  </div> </div>\n\n <p><strong>Example Output</strong></p>\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>NAME                                         AGE\nb4d045f0-6d58-11eb-98e7-b515603f1bc7-4c894   5d21h\n</code></pre>  </div> </div>\n </li>\n <li>To list the direct volume migration failures and their causes:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get dvm <span class=\"nt\">-l</span> <span class=\"nv\">migmigration</span><span class=\"o\">=</span>&lt;uid&gt; <span class=\"se\">\\</span>\n<span class=\"nt\">-o</span> go-template-file<span class=\"o\">=</span>go-cli-templates/dvm-display-failure-list.template\n</code></pre>  </div> </div>\n\n <p><strong>Example Output</strong></p>\n <div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">Name</span><span class=\"pi\">:</span>       <span class=\"s\">b4d045f0-6d58-11eb-98e7-b515603f1bc7-4c894</span>\n\n    <span class=\"s\">State</span><span class=\"pi\">:</span>  <span class=\"s\">Failed</span>\n    <span class=\"s\">Phase</span><span class=\"pi\">:</span>  <span class=\"s\">WaitForRsyncClientPodsCompleted</span>\n    <span class=\"s\">Message</span><span class=\"pi\">:</span>        <span class=\"s\">The migration has failed.  See</span><span class=\"pi\">:</span> <span class=\"s\">Errors.</span>\n\n<span class=\"na\">errors</span><span class=\"pi\">:</span>     <span class=\"pi\">[</span><span class=\"nv\">One or more pods are in error state</span><span class=\"pi\">]</span>\n</code></pre>  </div> </div>\n </li>\n</ul>\n\n<p>See <a href=\"https://docs.openshift.com/container-platform/4.7/migration/migrating_3_4/troubleshooting-3-4.html#migration-viewing-migration-crs_migrating-3-4\">Viewing migration custom resources</a> for more information.</p>\n\n<h2 id=\"debugging-backup-and-restore-resources-with-the-velero-cli\">Debugging <code class=\"language-plaintext highlighter-rouge\">backup</code> and <code class=\"language-plaintext highlighter-rouge\">restore</code> resources with the Velero CLI</h2>\n\n<p>You can debug <code class=\"language-plaintext highlighter-rouge\">backup</code> and <code class=\"language-plaintext highlighter-rouge\">restore</code> resources with the Velero command line interface (CLI). The Velero CLI is included in the <code class=\"language-plaintext highlighter-rouge\">velero</code> pod.</p>\n\n<p>Velero CLI examines lower-level information in the object storage associated with a <code class=\"language-plaintext highlighter-rouge\">Backup</code> or <code class=\"language-plaintext highlighter-rouge\">Restore</code> resource. This information can reveal why a resource was not restored or why a Velero operation failed.</p>\n\n<h3 id=\"velero-cli-commands\">Velero CLI commands</h3>\n\n<h4 id=\"syntax\">Syntax</h4>\n\n<p>Velero CLI commands use the following syntax:</p>\n\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc <span class=\"nb\">exec</span> <span class=\"si\">$(</span>oc get pods <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">-o</span> name | <span class=\"nb\">grep </span>velero<span class=\"si\">)</span> <span class=\"nt\">--</span> ./velero &lt;resource&gt; &lt;<span class=\"nb\">command</span><span class=\"o\">&gt;</span> &lt;resource_id&gt;\n</code></pre>  </div></div>\n<blockquote>\n <p>You can specify <code class=\"language-plaintext highlighter-rouge\">velero-&lt;pod&gt; -n openshift-migration</code> in place of <code class=\"language-plaintext highlighter-rouge\">$(oc get pods -n openshift-migration -o name | grep velero)</code>.</p>\n</blockquote>\n\n<p>For a full list of commands, run <code class=\"language-plaintext highlighter-rouge\">velero --help</code>:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc <span class=\"nb\">exec</span> <span class=\"si\">$(</span>oc get pods <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">-o</span> name | <span class=\"nb\">grep </span>velero<span class=\"si\">)</span> <span class=\"nt\">--</span> ./velero <span class=\"nt\">--help</span>\n</code></pre>  </div></div>\n\n<h4 id=\"velero-describe-command\">Velero <code class=\"language-plaintext highlighter-rouge\">describe</code> command</h4>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">describe</code> command provides a summary of warnings and errors associated with a Velero resource:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>velero &lt;resource&gt; describe &lt;resource_id&gt;\n</code></pre>  </div></div>\n<p><strong>Example</strong></p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc <span class=\"nb\">exec</span> <span class=\"si\">$(</span>oc get pods <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">-o</span> name | <span class=\"nb\">grep </span>velero<span class=\"si\">)</span> <span class=\"nt\">--</span> ./velero backup describe 0e44ae00-5dc3-11eb-9ca8-df7e5254778b-2d8ql\n</code></pre>  </div></div>\n\n<h4 id=\"velero-logs-command\">Velero <code class=\"language-plaintext highlighter-rouge\">logs</code> command</h4>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">logs</code> command provides a lower level output of the logs associated with a Velero resource:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>velero &lt;resource&gt; logs &lt;resource_id&gt;\n</code></pre>  </div></div>\n<p><strong>Example</strong></p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc <span class=\"nb\">exec</span> <span class=\"si\">$(</span>oc get pods <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">-o</span> name | <span class=\"nb\">grep </span>velero<span class=\"si\">)</span> <span class=\"nt\">--</span> ./velero restore logs ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf\n</code></pre>  </div></div>\n\n<h3 id=\"debugging-a-partial-failure-with-the-velero-logs-command\">Debugging a partial failure with the Velero <code class=\"language-plaintext highlighter-rouge\">logs</code> command</h3>\n\n<p>You can debug a partial failure by using the Velero <code class=\"language-plaintext highlighter-rouge\">logs</code> command to examine the <code class=\"language-plaintext highlighter-rouge\">restore</code> logs. A partial failure occurs when Velero encounters an issue but the issue does not cause a migration to fail.</p>\n\n<p>For example, if a custom resource (CR) cannot be restored because the custom resource definition (CRD) is missing or is a different version on the target cluster, Velero logs the issue and then processes the rest of the objects in the <code class=\"language-plaintext highlighter-rouge\">Backup</code> resource.</p>\n\n<blockquote>\n <p>In the future, Velero error reporting will be improved. See <a href=\"https://issues.redhat.com/browse/MIG-353\">MIG-353: Enhance Velero error reporting so problems that cause partial failures (and even full failures) are more visible in structured way</a></p>\n</blockquote>\n\n<p><strong>Debug example</strong></p>\n\n<p>The following example describes how to debug a partially failed <code class=\"language-plaintext highlighter-rouge\">restore</code> caused by GVK incompatibility. The CRD version on the source cluster differs from the CRD version on the target cluster. See the <a href=\"https://github.com/pranavgaikwad/mtc-breakfix/tree/master/03-Gvk\">GVK incompatibility exercise</a> for details.</p>\n\n<ol>\n <li>Obtain the <code class=\"language-plaintext highlighter-rouge\">MigMigration</code> instance associated with the partial failure:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> oc get migmigration ccc7c2d0-6017-11eb-afab-85d0007f5a19 <span class=\"nt\">-o</span> yaml\n</code></pre>  </div> </div>\n\n <p><strong>Example output</strong></p>\n\n <div class=\"language-yml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"na\">status</span><span class=\"pi\">:</span>\n   <span class=\"na\">conditions</span><span class=\"pi\">:</span>\n   <span class=\"pi\">-</span> <span class=\"na\">category</span><span class=\"pi\">:</span> <span class=\"s\">Warn</span>\n     <span class=\"na\">durable</span><span class=\"pi\">:</span> <span class=\"no\">true</span>\n     <span class=\"na\">lastTransitionTime</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">2021-01-26T20:48:40Z\"</span>\n     <span class=\"na\">message</span><span class=\"pi\">:</span> <span class=\"s1\">'</span><span class=\"s\">Final</span><span class=\"nv\"> </span><span class=\"s\">Restore</span><span class=\"nv\"> </span><span class=\"s\">openshift-migration/ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf:</span><span class=\"nv\"> </span><span class=\"s\">partially</span><span class=\"nv\"> </span><span class=\"s\">failed</span><span class=\"nv\"> </span><span class=\"s\">on</span><span class=\"nv\"> </span><span class=\"s\">destination</span><span class=\"nv\"> </span><span class=\"s\">cluster'</span>\n     <span class=\"na\">status</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">True\"</span>\n     <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">VeleroFinalRestorePartiallyFailed</span>\n   <span class=\"pi\">-</span> <span class=\"na\">category</span><span class=\"pi\">:</span> <span class=\"s\">Advisory</span>\n     <span class=\"na\">durable</span><span class=\"pi\">:</span> <span class=\"no\">true</span>\n     <span class=\"na\">lastTransitionTime</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">2021-01-26T20:48:42Z\"</span>\n     <span class=\"na\">message</span><span class=\"pi\">:</span> <span class=\"s\">The migration has completed with warnings, please look at `Warn` conditions.</span>\n     <span class=\"na\">reason</span><span class=\"pi\">:</span> <span class=\"s\">Completed</span>\n     <span class=\"na\">status</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">True\"</span>\n     <span class=\"na\">type</span><span class=\"pi\">:</span> <span class=\"s\">SucceededWithWarnings</span>\n</code></pre>  </div> </div>\n <p><a href=\"https://gist.github.com/jwmatthews/001ff42bf5e712ba2eab92df306ed34e\">Full output</a></p>\n </li>\n <li>Check the status of the <code class=\"language-plaintext highlighter-rouge\">restore</code> resource by running the <code class=\"language-plaintext highlighter-rouge\">describe</code> command:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"nv\">$ </span>oc <span class=\"nb\">exec</span> <span class=\"si\">$(</span>oc get pods <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">-o</span> name | <span class=\"nb\">grep </span>velero<span class=\"si\">)</span> <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">--</span> ./velero restore describe ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf\n</code></pre>  </div> </div>\n\n <p><strong>Example output</strong></p>\n\n <div class=\"language-yml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"na\">Phase</span><span class=\"pi\">:</span>  <span class=\"s\">PartiallyFailed (run 'velero restore logs ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf' for more information)</span>\n\n <span class=\"na\">Errors</span><span class=\"pi\">:</span>\n   <span class=\"na\">Velero</span><span class=\"pi\">:</span>     <span class=\"s\">&lt;none&gt;</span>\n   <span class=\"na\">Cluster</span><span class=\"pi\">:</span>    <span class=\"s\">&lt;none&gt;</span>\n   <span class=\"na\">Namespaces</span><span class=\"pi\">:</span>\n     <span class=\"na\">gvk-demo</span><span class=\"pi\">:</span>  <span class=\"s\">error restoring gvkdemoes.konveyor.openshift.io/gvk-demo/gvk-demo</span><span class=\"pi\">:</span> <span class=\"s\">the server could not find the requested resource</span>\n</code></pre>  </div> </div>\n <p><a href=\"https://gist.github.com/9a3ec8f51e12b84f8bb995286223bdda\">Full output</a></p>\n </li>\n <li>Check the <code class=\"language-plaintext highlighter-rouge\">restore</code> logs by running the <code class=\"language-plaintext highlighter-rouge\">logs</code> command:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"nv\">$ </span>oc <span class=\"nb\">exec</span> <span class=\"si\">$(</span>oc get pods <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">-o</span> name | <span class=\"nb\">grep </span>velero<span class=\"si\">)</span> <span class=\"nt\">-n</span> openshift-migration <span class=\"nt\">--</span> ./velero restore logs ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf\n</code></pre>  </div> </div>\n\n <p><strong>Example output</strong></p>\n\n <div class=\"language-yml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code> <span class=\"s\">time=\"2021-01-26T20:48:37Z\" level=info msg=\"Attempting to restore GvkDemo</span><span class=\"pi\">:</span> <span class=\"s\">gvk-demo\" logSource=\"pkg/restore/restore.go:1107\" restore=openshift-migration/ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf</span>\n <span class=\"s\">time=\"2021-01-26T20:48:37Z\" level=info msg=\"error restoring gvk-demo</span><span class=\"pi\">:</span> <span class=\"s\">the server could not find the requested resource\" logSource=\"pkg/restore/restore.go:1170\" restore=openshift-migration/ccc7c2d0-6017-11eb-afab-85d0007f5a19-x4lbf</span>\n</code></pre>  </div> </div>\n\n <p><a href=\"https://gist.github.com/jwmatthews/7dc7ed9eb0c4d0611f30675074b9b7d7\">Full output</a></p>\n\n <p>The <code class=\"language-plaintext highlighter-rouge\">restore</code> log error message, <code class=\"language-plaintext highlighter-rouge\">the server could not find the requested resource</code>, indicates the cause of the partially failed migration.</p>\n </li>\n</ol>\n\n<h2 id=\"error-messages\">Error messages</h2>\n\n<h3 id=\"ca-certificate-error-when-logging-in-to-the-mtc-console-for-the-first-time\">CA certificate error when logging in to the MTC console for the first time</h3>\n\n<p>The following error message might appear when you log in to the MTC console for the first time:</p>\n\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>A certificate error has occurred, likely caused by using self-signed CA certificates in one of the clusters. Navigate to the following URL and accept the certificate:\n`https://www.example.com:6443/.well-known/oauth-authorization-server`.\n\nIf an \"Unauthorized\" message appears after you have accepted the certificate, refresh the web page.\n\nTo fix this issue permanently, add the certificate to your web browser's trust store.\n</code></pre>  </div></div>\n\n<p>Possible causes are self-signed certificates or network access issues.</p>\n\n<p>Self-signed CA certificates:</p>\n\n<ul>\n <li>You can navigate to the <code class=\"language-plaintext highlighter-rouge\">oauth-authorization-server</code> URL and accept the certificate.</li>\n <li>You can add self-signed certificates for the API server, OAuth server, and routes to your web browser’s trusted store.</li>\n</ul>\n\n<p>Network access:</p>\n\n<ul>\n <li>You can inspect the elements of the MTC console with your browser’s web inspector to view the network connections.</li>\n <li>\n <p>MTC 1.3.1 and earlier: The MTC console performs OAuth authentication on the client side.</p>\n\n <p>The console requires uninterrupted network access to the API server and the OAuth server.</p>\n </li>\n <li>\n <p>MTC 1.3.2 and later: OAuth authentication is performed on the backend.</p>\n\n <p>The console requires uninterrupted network access to the Node.js server, which provides the JavaScript bundle and performs OAuth authentication, and the API server. See <a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=1878824\">BZ#1878824</a>.</p>\n </li>\n</ul>\n\n<h3 id=\"connection-time-out-after-accepting-ca-certificate\">Connection time-out after accepting CA certificate</h3>\n\n<p>If you acce[t] a self-signed certificate and a blank page appears, followed by a <code class=\"language-plaintext highlighter-rouge\">Connection has timed out</code> message, the likely cause is a web proxy blocking access to the OAuth server.</p>\n\n<p>Configure the web proxy configuration to allow access to the <code class=\"language-plaintext highlighter-rouge\">oauth-authorization-server</code> URL. See <a href=\"https://bugzilla.redhat.com/show_bug.cgi?id=1890675\">BZ#1890675</a>.</p>\n\n<h2 id=\"using-must-gather\">Using <code class=\"language-plaintext highlighter-rouge\">must-gather</code></h2>\n\n<p>You can use the <code class=\"language-plaintext highlighter-rouge\">must-gather</code> tool to collect information for troubleshooting or for opening a customer support case on the <a href=\"https://access.redhat.com/\">Red Hat Customer Portal</a>. The <code class=\"language-plaintext highlighter-rouge\">openshift-migration-must-gather-rhel8</code> image collects migration-specific logs and Custom Resource data that are not collected by the default <code class=\"language-plaintext highlighter-rouge\">must-gather</code> image.</p>\n\n<p>Run the <code class=\"language-plaintext highlighter-rouge\">must-gather</code> command on your cluster:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc adm must-gather <span class=\"nt\">--image</span><span class=\"o\">=</span>openshift-migration-must-gather-rhel8:v1.3.0\n</code></pre>  </div></div>\n\n<p>The <code class=\"language-plaintext highlighter-rouge\">must-gather</code> tool generates a local directory that contains the collected data.</p>\n\n<h2 id=\"direct-volume-migration-fails-to-complete\">Direct volume migration fails to complete</h2>\n\n<p>For direct volume migrations, we create a few dependencies:</p>\n<ol>\n <li>Transfer pod on the destination cluster in target namespace. This pod\n has rsync daemon container and stunnel container</li>\n <li>Stunnel service on the destination cluster in target namespace, this\n creates the networking presence for the stunnel container in kubernetes</li>\n <li>Stunnel route on the destination cluster in target namespace, this\n creates a route to be exposed on the internet</li>\n <li>Stunnel pod on the source cluster in source namespace, this connects to\n the target stunnel container in transfer pod through stunnel route on the\n target namespace</li>\n <li>Rsync client pods on the source cluster in source namespace, this runs\n the actual rsync command for moving the PVC data.</li>\n</ol>\n\n<p>If direct volume migration fails to complete, it could be one of the following\nbuckets of errors:</p>\n\n<ol>\n <li>\n <p>Error in creating dependencies: If creating any of the above dependencies\n fails, it could lead to a failure. The error message will be present in\n DVM status and in the errors fields. Use the dvm failure list command to\n find this.</p>\n </li>\n <li>\n <p>Stuck in waiting for dependencies to be healthy: It could be the case\n that the pods on either source or destination is not running or the route\n is not admitted. In both these cases, DVM is hang until the pod is\n running or route is admitted. When the pods are stuck in a non-healthy\n state, you will find a Warning in 10 mins of DVM being stuck here. Use\n the dvm command to see warning on the dvm status</p>\n </li>\n <li>\n <p>Rsync exits with error: this happens when all the dependencies are met\n and healthy and the rysnc fail because of some reason. The dvm controller\n does not clean up the failed rsync client pods so the logs can be inspected.</p>\n </li>\n</ol>\n\n<h4 id=\"example-of-debugging-with-dependency-pod-in-pending-state\">Example of debugging with dependency pod in pending state:</h4>\n\n<p>A very likely cause of direct volume migration failing to complete is the\n Rsync transfer pods on the target cluster remain in a <code class=\"language-plaintext highlighter-rouge\">Pending</code> state.</p>\n\n<p>MTC migrates namespaces with all annotations in order to preserve security context constraints and scheduling requirements. During direct volume migration, MTC creates Rsync transfer pods on the target cluster in the namespaces that were migrated from the source cluster. If the target cluster does not have the same node labels as the source cluster, the Rsync transfer pods cannot be scheduled.</p>\n\n<p>You can check the <code class=\"language-plaintext highlighter-rouge\">migmigration</code> CR status:</p>\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc describe migmigration 88435fe0-c9f8-11e9-85e6-5d593ce65e10 <span class=\"nt\">-n</span> openshift-migration\n</code></pre>  </div></div>\n\n<p>The output displays the following <code class=\"language-plaintext highlighter-rouge\">status</code> message:</p>\n<div class=\"language-plaintext highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code>Some or all transfer pods are not running for more than 10 mins on destination cluster\n</code></pre>  </div></div>\n\n<p>To resolve this issue, perform the following steps:</p>\n\n<ol>\n <li>Obtain the value of the <code class=\"language-plaintext highlighter-rouge\">openshift.io/node-selector</code> annotation of the migrated namespaces on the source cluster:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc get namespace <span class=\"nt\">-o</span> yaml\n</code></pre>  </div> </div>\n </li>\n <li>Add the <code class=\"language-plaintext highlighter-rouge\">openshift.io/node-selector</code> annotation to each migrated namespace on the target cluster:\n <div class=\"language-yml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">v1</span>\n<span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Namespace</span>\n<span class=\"na\">metadata</span><span class=\"pi\">:</span>\n  <span class=\"na\">annotations</span><span class=\"pi\">:</span>\n<span class=\"err\"> </span><span class=\"s\">openshift.io/node-selector</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">region=east\"</span>\n<span class=\"nn\">...</span>\n</code></pre>  </div> </div>\n </li>\n <li>Re-run the migration plan.</li>\n</ol>\n\n<h2 id=\"previewing-metrics-on-local-prometheus-server\">Previewing metrics on local Prometheus server</h2>\n\n<p>You can use <code class=\"language-plaintext highlighter-rouge\">must-gather</code> to create a metrics data directory dump from the last day:</p>\n\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc adm must-gather <span class=\"nt\">--image</span> quay.io/konveyor/must-gather:latest <span class=\"nt\">--</span> /usr/bin/gather_metrics_dump\n</code></pre>  </div></div>\n\n<p>You can view the data with a <a href=\"https://github.com/konveyor/must-gather#preview-metrics-on-local-prometheus-server\">local Prometheus instance</a>.</p>\n\n<h2 id=\"performance-metrics\">Performance metrics</h2>\n\n<p>For information about the metrics recorded by the MTC controller, see the <a href=\"https://github.com/konveyor/mig-operator/blob/master/docs/usage/Metrics.md#accessing-mig-controller-prometheus-metrics\"><code class=\"language-plaintext highlighter-rouge\">mig-operator</code> documentation</a>.</p>\n\n<p>This documentation includes <a href=\"https://github.com/konveyor/mig-operator/blob/master/docs/usage/Metrics.md#useful-queries\">useful queries</a> for performance monitoring.</p>\n\n<h2 id=\"cleaning-up-a-failed-migration\">Cleaning up a failed migration</h2>\n\n<h3 id=\"deleting-resources\">Deleting resources</h3>\n\n<p>Ensure that stage pods are cleaned up. If a migration fails during stage or copy, the stage pods are retained to allow debugging. Before retrying a migration, you must delete the stage pods manually.</p>\n\n<h3 id=\"unquiescing-an-application\">Unquiescing an application</h3>\n\n<p>If your application was quiesced during migration, you should <code class=\"language-plaintext highlighter-rouge\">unquiesce</code> it by scaling it back to its initial replica count.</p>\n\n<p>This can be done manually by editing the deployment primitive (<code class=\"language-plaintext highlighter-rouge\">Deployment</code>, <code class=\"language-plaintext highlighter-rouge\">DeploymentConfig</code>, etc.) and setting the <code class=\"language-plaintext highlighter-rouge\">spec.replicas</code> field back to its original, non-zero value:</p>\n\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc edit deployment &lt;deployment_name&gt;\n</code></pre>  </div></div>\n\n<p>Alternatively, you can scale your deployment with the <code class=\"language-plaintext highlighter-rouge\">oc scale</code> command:</p>\n\n<div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc scale deployment &lt;deployment_name&gt; <span class=\"nt\">--replicas</span><span class=\"o\">=</span>&lt;desired_replicas&gt;\n</code></pre>  </div></div>\n\n<h3 id=\"labels-for-premigration-settings\">Labels for premigration settings</h3>\n\n<p>When a source application is quiesced during migration, MTC adds a label indicating the original replica count to the <code class=\"language-plaintext highlighter-rouge\">deployment</code> resource:</p>\n\n<div class=\"language-yaml highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"na\">apiVersion</span><span class=\"pi\">:</span> <span class=\"s\">extensions/v1beta1</span>\n<span class=\"na\">kind</span><span class=\"pi\">:</span> <span class=\"s\">Deployment</span>\n<span class=\"na\">metadata</span><span class=\"pi\">:</span>\n  <span class=\"na\">annotations</span><span class=\"pi\">:</span>\n    <span class=\"s\">deployment.kubernetes.io/revision</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">1\"</span>\n    <span class=\"s\">migration.openshift.io/preQuiesceReplicas</span><span class=\"pi\">:</span> <span class=\"s2\">\"</span><span class=\"s\">1\"</span>\n</code></pre>  </div></div>\n\n<h3 id=\"deleting-the-mtc-operator-and-resources\">Deleting the MTC Operator and resources</h3>\n\n<p>The following procedure removes the MTC Operator and cluster-scoped resources:</p>\n\n<ol>\n <li>\n <p>Delete the Migration Controller and its resources:</p>\n\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete migrationcontroller &lt;resource_name&gt;\n</code></pre>  </div> </div>\n\n <p>Wait for the MTC Operator to finish deleting the resources.</p>\n </li>\n <li>\n <p>Uninstall the MTC Operator:</p>\n\n <ul>\n <li>OpenShift 4: Uninstall the Operator in the <a href=\"https://docs.openshift.com/container-platform/4.7/operators/olm-deleting-operators-from-cluster.html\">web console</a> or by running the following command:</li>\n </ul>\n\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete ns openshift-migration\n</code></pre>  </div> </div>\n\n <ul>\n <li>OpenShift 3: Uninstall the operator by deleting it:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete <span class=\"nt\">-f</span> operator.yml\n</code></pre>  </div> </div>\n </li>\n </ul>\n </li>\n <li>\n <p>Delete the cluster-scoped resources:</p>\n <ul>\n <li>Migration custom resource definition:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete <span class=\"si\">$(</span>oc get crds <span class=\"nt\">-o</span> name | <span class=\"nb\">grep</span> <span class=\"s1\">'migration.openshift.io'</span><span class=\"si\">)</span>\n</code></pre>  </div> </div>\n </li>\n <li>Velero custom resource definition:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete <span class=\"si\">$(</span>oc get crds <span class=\"nt\">-o</span> name | <span class=\"nb\">grep</span> <span class=\"s1\">'velero'</span><span class=\"si\">)</span>\n</code></pre>  </div> </div>\n </li>\n <li>Migration cluster role:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete <span class=\"si\">$(</span>oc get clusterroles <span class=\"nt\">-o</span> name | <span class=\"nb\">grep</span> <span class=\"s1\">'migration.openshift.io'</span><span class=\"si\">)</span>\n</code></pre>  </div> </div>\n </li>\n <li>Migration-operator cluster role:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete clusterrole migration-operator\n</code></pre>  </div> </div>\n </li>\n <li>Velero cluster role:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete <span class=\"si\">$(</span>oc get clusterroles <span class=\"nt\">-o</span> name | <span class=\"nb\">grep</span> <span class=\"s1\">'velero'</span><span class=\"si\">)</span>\n</code></pre>  </div> </div>\n </li>\n <li>Migration cluster role bindings:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete <span class=\"si\">$(</span>oc get clusterrolebindings <span class=\"nt\">-o</span> name | <span class=\"nb\">grep</span> <span class=\"s1\">'migration.openshift.io'</span><span class=\"si\">)</span>\n</code></pre>  </div> </div>\n </li>\n <li>Migration-operator cluster role bindings:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete clusterrolebindings migration-operator\n</code></pre>  </div> </div>\n </li>\n <li>Velero cluster role bindings:\n <div class=\"language-sh highlighter-rouge\"><div class=\"highlight\"><pre class=\"highlight\"><code><span class=\"nv\">$ </span>oc delete <span class=\"si\">$(</span>oc get clusterrolebindings <span class=\"nt\">-o</span> name | <span class=\"nb\">grep</span> <span class=\"s1\">'velero'</span><span class=\"si\">)</span>\n</code></pre>  </div> </div>\n </li>\n </ul>\n </li>\n</ol>\n","dir":"/","name":"05-troubleshooting.md","path":"05-troubleshooting.md","url":"/05-troubleshooting.html"},{"title":"Postmigration considerations","layout":"default","content":"<h1 id=\"postmigration-considerations\">Postmigration considerations</h1>\n\n<p>Now that the migration is completed, there are some considerations to keep in mind once you migrated to OpenShift 4.</p>\n\n<h2 id=\"operators\">Operators</h2>\n\n<p>As you might know in OpenShift 4, Operators are a really important piece of the platform.</p>\n\n<p>An Operator is a method of packaging, deploying and managing a Kubernetes-native application. A Kubernetes-native application is an application that is both deployed on Kubernetes and managed using the Kubernetes APIs and kubectl tooling.</p>\n\n<p>Operators provide:</p>\n\n<ul>\n <li>Repeatability of installation and upgrade.</li>\n <li>Constant health checks of every system component.</li>\n <li>Over-the-air (OTA) updates for OpenShift components and ISV content.</li>\n <li>A place to encapsulate knowledge from field engineers and spread it to all users, not just one or two.</li>\n</ul>\n\n<p>In OpenShift 4 we have an operator marketplace with different categories depending on their supportability level:</p>\n\n<table>\n <thead>\n <tr>\n <th>Category</th>\n <th>Description</th>\n </tr>\n </thead>\n <tbody>\n <tr>\n <td>Red Hat Operators</td>\n <td>Red Hat products packaged and shipped by Red Hat. Supported by Red Hat.</td>\n </tr>\n <tr>\n <td>Certified Operators</td>\n <td>Products from leading independent software vendors (ISVs). Red Hat partners with ISVs to package and ship. Supported by the ISV.</td>\n </tr>\n <tr>\n <td>Community Operators</td>\n <td>Optionally-visible software maintained by relevant representatives in the <a href=\"https://github.com/operator-framework/community-operators\">operator-framework/community-operators</a> GitHub repository. No official support.</td>\n </tr>\n <tr>\n <td>Custom Operators</td>\n <td>Operators you add to the cluster yourself. If you have not added any Custom Operators, the Custom category does not appear in the Web console on your OperatorHub.</td>\n </tr>\n <tr>\n <td> </td>\n <td> </td>\n </tr>\n </tbody>\n</table>\n\n<p><strong>Operators maturity levels</strong></p>\n\n<p>The level of sophistication of the management logic encapsulated within an Operator can vary. This logic is also in general highly dependent on the type of the service represented by the Operator.</p>\n\n<p>One can however generalize the scale of the maturity of an Operator’s encapsulated operations for certain set of capabilities that most Operators can include. To this end, the following Operator Maturity model defines five phases of maturity for generic day two operations of an Operator:</p>\n\n<p><img src=\"./images/operator-maturity-levels.png\" alt=\"Operator Maturity Levels\" /></p>\n\n<h3 id=\"when-you-might-want-to-move-to-operators\"><strong>When you might want to move to operators</strong></h3>\n\n<p>If you were using the Service Broker or some OpenShift Templates in OpenShift 3.11 in order to run a specific service such as MongoDB, PostgreSQL, etc. You might want to move to the specific operators for such technologies.</p>\n\n<p>For example, if your application uses a MongoDB database, it will be very easy to use the MongoDB Operator in order to deploy and manage the MongoDB instance. The operator will take care of the MongoDB instance lifecycle helping you to focus on your application.</p>\n\n<h3 id=\"accessing-the-operatorhub-marketplace\"><strong>Accessing the OperatorHub marketplace</strong></h3>\n\n<p>OpenShift 4 console features an operator marketplace called OperatorHub, you will find it under <code class=\"language-plaintext highlighter-rouge\">Operators -&gt; OperatorHub</code>.</p>\n\n<p><img src=\"./images/openshif4-operatorhub.png\" alt=\"OpenShift4 OperatorHub\" /></p>\n\n<p>You can use OperatorHub within the OpenShift Console in order to search and install operators. You will be able to manage the installed operators using this same UI.</p>\n\n<h3 id=\"creating-your-own-operators\"><strong>Creating your own operators</strong></h3>\n\n<p>You might have some applications created by internal teams that are currently being deployed manually or using other methods that do not support managing the full lifecycle of the application. On top of that the operations team might need to ensure those applications are up and running.</p>\n\n<p>In such cases, creating an operator to manage the full lifecycle of your application can be very beneficial, you will have the operational knowledge coded inside the operator. That way your operation teams can focus on more interesting tasks since the operational knowledge will be coded inside the operator.</p>\n\n<p>The <a href=\"https://github.com/operator-framework/operator-sdk\">Operator SDK</a> is a framework that uses the <a href=\"https://github.com/kubernetes-sigs/controller-runtime\">controller-runtime</a> library to make writing operators easier by providing:</p>\n\n<ul>\n <li>High level APIs and abstractions to write the operational logic more intuitively</li>\n <li>Tools for scaffolding and code generation to bootstrap a new project fast</li>\n <li>Extensions to cover common operator use cases</li>\n</ul>\n\n<p>Operator can be written using Go, Ansible or even leveraging existing Helm charts.</p>\n\n<p>You can learn more about how to create your own operators in the <a href=\"https://learn.openshift.com/operatorframework/\">Building Operators on OpenShift</a> interactive scenarios.</p>\n\n<h3 id=\"additional-operator-resources\"><strong>Additional operator resources</strong></h3>\n\n<p>You can continue learning about operators in the following resources:</p>\n\n<ul>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/operators/understanding/olm-what-operators-are.html\">OpenShift 4 Operators Documentation</a></li>\n <li><a href=\"https://docs.openshift.com/container-platform/4.7/operators/operator_sdk/osdk-getting-started.html\">OpenShift 4 Getting started with the Operator SDK</a></li>\n <li><a href=\"https://www.openshift.com/learn/topics/operators\">OpenShift Learn Operators</a></li>\n <li><a href=\"https://sdk.operatorframework.io/\">Operator SDK Documentation</a></li>\n</ul>\n","dir":"/","name":"06-post-migration-considerations.md","path":"06-post-migration-considerations.md","url":"/06-post-migration-considerations.html"},{"title":"Index","layout":"default","content":"<h1 id=\"best-practices-for-migrating-from-openshiftcontainerplatform3to4\">Best practices for migrating from OpenShift Container Platform 3 to 4</h1>\n\n<p>This guide provides recommendations and best practices for migrating from OpenShift Container Platform 3.9+ to OpenShift 4.x with the Migration Toolkit for Containers (MTC). The recommendations are organized into the sections listed on the left pane.</p>\n\n<p>Feel free to raise issues or submit pull requests on the repository: <a href=\"https://github.com/redhat-cop/openshift-migration-best-practices/\">https://github.com/redhat-cop/openshift-migration-best-practices/</a>.</p>\n\n<p><strong>DISCLAIMER:</strong> This document is not a Red Hat supported document. For supported documentation please use the <a href=\"https://access.redhat.com/documentation/en-us/openshift_container_platform/4.7/html/migration_toolkit_for_containers/index\">Migration Toolkit for Containers official documentation</a>.</p>\n","dir":"/","name":"index.md","path":"index.md","url":"/"}]